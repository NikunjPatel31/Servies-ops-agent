#!/usr/bin/env python3
"""
Multi-Endpoint API Agent
Handles multiple ITSM endpoints with automatic user resolution and dynamic filtering
"""

import json
import requests
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from config.api_config import APIConfig

class MultiEndpointAgent:
    def __init__(self):
        self.config = APIConfig()
        self.access_token = None
        self.token_expiry = None
        
        # Cached mappings
        self.user_mapping = {}
        self.urgency_mapping = {}
        self.service_catalog_mapping = {}
        self.status_mapping = {}
        self.category_mapping = {}
        self.department_mapping = {}

        # Mapping loaded flags
        self.user_mapping_loaded = False
        self.urgency_mapping_loaded = False
        self.service_catalog_mapping_loaded = False
        self.status_mapping_loaded = False
        self.category_mapping_loaded = False
        self.department_mapping_loaded = False

        # Train the agent with comprehensive knowledge
        self.train_from_data()
        
        # API endpoint configurations
        self.endpoints = {
            'requests': {
                'url': f"{self.config.BASE_URL}/api/request/search/byqual",
                'method': 'POST',
                'description': 'Search and filter IT service requests',
                'filters': ['status', 'priority', 'urgency', 'assignee', 'requester', 'category', 'subject', 'description', 'tags', 'date']
            },
            'urgency': {
                'url': f"{self.config.BASE_URL}/api/urgency/search/byqual",
                'method': 'POST',
                'description': 'Get urgency levels mapping',
                'filters': []
            },
            'service_catalog': {
                'url': f"{self.config.BASE_URL}/api/service_catalog/search/byqual",
                'method': 'POST',
                'description': 'Search service catalog items',
                'filters': ['category', 'status', 'name', 'description']
            },
            'users': {
                'url': f"{self.config.BASE_URL}/api/technician/active/list",
                'method': 'GET',
                'description': 'Get active technicians/users list',
                'filters': []
            }
        }
    
    def get_access_token(self):
        """Get or refresh access token"""
        if self.access_token and self.token_expiry and datetime.now() < self.token_expiry:
            return self.access_token

        try:
            print("ğŸ”‘ Fetching new access token...")

            # Check if TOKEN_URL is configured
            if not hasattr(self.config, 'TOKEN_URL') or not self.config.TOKEN_URL:
                print("âš ï¸ TOKEN_URL not configured, using fallback token logic")
                # For testing purposes, return a dummy token
                self.access_token = "dummy_token_for_testing"
                self.token_expiry = datetime.now() + timedelta(hours=1)
                return self.access_token

            headers = {
                'Accept': '*/*',
                'Accept-Language': 'en-GB,en;q=0.9',
                'Authorization': self.config.BASIC_AUTH,
                'Connection': 'keep-alive',
                'Content-Type': 'application/x-www-form-urlencoded',
                'Origin': self.config.BASE_URL,
                'Referer': f'{self.config.BASE_URL}/login?redirectFrom=%2Ft%2Frequest%2F',
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36'
            }

            # Use URL-encoded form data as raw string (matching the curl exactly)
            data = f'username={self.config.USERNAME_ENCODED}&password={self.config.PASSWORD_ENCODED}&grant_type=password'

            response = requests.post(
                self.config.TOKEN_URL,
                headers=headers,
                data=data,  # Now using raw string data
                verify=False,
                timeout=self.config.REQUEST_TIMEOUT
            )

            if response.status_code == 200:
                token_data = response.json()
                self.access_token = token_data.get('access_token')
                expires_in = token_data.get('expires_in', 3600)
                self.token_expiry = datetime.now() + timedelta(seconds=expires_in - 60)

                print(f"âœ… Token obtained successfully (expires in {expires_in}s)")
                return self.access_token
            else:
                print(f"âŒ Token request failed: {response.status_code} - {response.text}")
                # Try to refresh token one more time
                print("ğŸ”„ Retrying token request...")
                self.access_token = None
                self.token_expiry = None
                return self.get_access_token_retry()

        except Exception as e:
            print(f"âŒ Token error: {str(e)}")
            return None

    def get_access_token_retry(self):
        """Retry token acquisition once"""
        try:
            headers = {
                'Accept': '*/*',
                'Accept-Language': 'en-GB,en;q=0.9',
                'Authorization': self.config.BASIC_AUTH,
                'Connection': 'keep-alive',
                'Content-Type': 'application/x-www-form-urlencoded',
                'Origin': self.config.BASE_URL,
                'Referer': f'{self.config.BASE_URL}/login?redirectFrom=%2Ft%2Frequest%2F',
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36'
            }

            # Use URL-encoded form data as raw string (matching the curl exactly)
            data = f'username={self.config.USERNAME_ENCODED}&password={self.config.PASSWORD_ENCODED}&grant_type=password'

            response = requests.post(
                self.config.TOKEN_URL,
                headers=headers,
                data=data,  # Now using raw string data
                verify=False,
                timeout=self.config.REQUEST_TIMEOUT
            )

            if response.status_code == 200:
                token_data = response.json()
                self.access_token = token_data.get('access_token')
                expires_in = token_data.get('expires_in', 3600)
                self.token_expiry = datetime.now() + timedelta(seconds=expires_in - 60)

                print(f"âœ… Token retry successful (expires in {expires_in}s)")
                return self.access_token
            else:
                print(f"âŒ Token retry failed: {response.status_code}")
                return None

        except Exception as e:
            print(f"âŒ Token retry error: {str(e)}")
            return None
    
    def make_api_request(self, endpoint_name: str, payload: Dict = None, params: Dict = None, retry_count: int = 0):
        """Make API request to specified endpoint with token refresh"""
        if endpoint_name not in self.endpoints:
            return {"error": f"Unknown endpoint: {endpoint_name}"}

        endpoint = self.endpoints[endpoint_name]
        auth_token = self.get_access_token()

        if not auth_token:
            return {"error": "Failed to obtain access token"}

        headers = {
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',
            'Authorization': f'Bearer {auth_token}',
            'Connection': 'keep-alive',
            'Content-Type': 'application/json',
            'Origin': self.config.BASE_URL,
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'
        }

        try:
            if endpoint['method'] == 'POST':
                response = requests.post(
                    endpoint['url'],
                    headers=headers,
                    json=payload or {},
                    params=params,
                    verify=False,
                    timeout=self.config.REQUEST_TIMEOUT
                )
            else:  # GET
                response = requests.get(
                    endpoint['url'],
                    headers=headers,
                    params=params,
                    verify=False,
                    timeout=self.config.REQUEST_TIMEOUT
                )

            if response.status_code == 200:
                return response.json()
            elif response.status_code == 401 and retry_count == 0:
                # Token expired, refresh and retry
                print("ğŸ”„ Token expired, refreshing and retrying...")
                self.access_token = None
                self.token_expiry = None
                return self.make_api_request(endpoint_name, payload, params, retry_count + 1)
            else:
                error_msg = f"API request failed: {response.status_code}"
                if response.text:
                    error_msg += f" - {response.text[:200]}"
                return {"error": error_msg}

        except Exception as e:
            return {"error": f"Request error: {str(e)}"}
    
    def get_user_mapping(self):
        """Get user mapping from the API"""
        if self.user_mapping_loaded:
            return self.user_mapping
        
        print("ğŸ‘¥ Fetching user mapping...")
        response = self.make_api_request('users')
        
        if 'error' in response:
            print(f"âŒ User mapping failed: {response['error']}")
            return {}
        
        # Parse user response - it's a dict with user IDs as keys
        self.user_mapping = {}
        for user_id, user_sessions in response.items():
            if user_sessions and len(user_sessions) > 0:
                user_data = user_sessions[0]  # Take first session data
                user_name = user_data.get('name', '').lower()
                email = user_data.get('email', '').lower()
                
                if user_name:
                    self.user_mapping[user_name] = int(user_id)
                if email and email != user_name:
                    self.user_mapping[email] = int(user_id)
        
        self.user_mapping_loaded = True
        print(f"âœ… User mapping loaded: {len(self.user_mapping)} users")
        return self.user_mapping
    
    def get_urgency_mapping(self):
        """Get urgency mapping from the API"""
        if self.urgency_mapping_loaded:
            return self.urgency_mapping
        
        print("âš¡ Fetching urgency mapping...")
        response = self.make_api_request('urgency')
        
        if 'error' in response:
            print(f"âŒ Urgency mapping failed: {response['error']}")
            return {}
        
        # Parse urgency response
        self.urgency_mapping = {}
        if isinstance(response, list):
            for urgency in response:
                name = urgency.get('name', '').lower()
                system_name = urgency.get('systemName', '').lower()
                urgency_id = urgency.get('id')
                
                if name and urgency_id:
                    self.urgency_mapping[name] = urgency_id
                if system_name and system_name != name:
                    self.urgency_mapping[system_name] = urgency_id
        
        self.urgency_mapping_loaded = True
        print(f"âœ… Urgency mapping loaded: {len(self.urgency_mapping)} levels")
        return self.urgency_mapping
    
    def get_service_catalog_mapping(self):
        """Get service catalog mapping from the API"""
        if self.service_catalog_mapping_loaded:
            return self.service_catalog_mapping
        
        print("ğŸ“‹ Fetching service catalog mapping...")
        response = self.make_api_request('service_catalog', params={'offset': 0, 'size': 1000})
        
        if 'error' in response:
            print(f"âŒ Service catalog mapping failed: {response['error']}")
            return {}
        
        # Parse service catalog response
        self.service_catalog_mapping = {}
        if isinstance(response, list):
            for catalog in response:
                name = catalog.get('name', '').lower()
                subject = catalog.get('subject', '').lower()
                catalog_id = catalog.get('id')
                
                if name and catalog_id:
                    self.service_catalog_mapping[name] = catalog_id
                if subject and subject != name:
                    self.service_catalog_mapping[subject] = catalog_id
        
        self.service_catalog_mapping_loaded = True
        print(f"âœ… Service catalog mapping loaded: {len(self.service_catalog_mapping)} items")
        return self.service_catalog_mapping

    def detect_endpoint_from_prompt(self, user_prompt: str) -> str:
        """Detect which endpoint to use based on user prompt"""
        prompt_lower = user_prompt.lower()

        # Request-related keywords
        request_keywords = [
            'request', 'ticket', 'incident', 'issue', 'problem', 'task',
            'assigned', 'assignee', 'technician', 'status', 'priority',
            'created', 'updated', 'subject', 'description'
        ]

        # Service catalog keywords
        catalog_keywords = [
            'service catalog', 'catalog', 'service', 'template',
            'on-boarding', 'off-boarding', 'laptop', 'employee'
        ]

        # User-related keywords
        user_keywords = [
            'user', 'technician', 'employee', 'staff', 'person',
            'who is', 'user details', 'technician details'
        ]

        # Urgency-related keywords
        urgency_keywords = [
            'urgency', 'urgent', 'urgency level', 'urgency mapping'
        ]

        # Count keyword matches
        request_score = sum(1 for keyword in request_keywords if keyword in prompt_lower)
        catalog_score = sum(1 for keyword in catalog_keywords if keyword in prompt_lower)
        user_score = sum(1 for keyword in user_keywords if keyword in prompt_lower)
        urgency_score = sum(1 for keyword in urgency_keywords if keyword in prompt_lower)

        # Determine endpoint based on highest score
        scores = {
            'requests': request_score,
            'service_catalog': catalog_score,
            'users': user_score,
            'urgency': urgency_score
        }

        # Default to requests if no clear winner
        detected_endpoint = max(scores, key=scores.get)
        if scores[detected_endpoint] == 0:
            detected_endpoint = 'requests'

        print(f"ğŸ¯ Detected endpoint: {detected_endpoint} (scores: {scores})")
        return detected_endpoint

    def resolve_user_references(self, user_prompt: str) -> Dict[str, int]:
        """Resolve user names to IDs in the prompt"""
        resolved_users = {}

        import re

        # First try to get user mapping from API
        user_mapping = self.get_user_mapping()

        # Patterns to find user references
        user_patterns = [
            r'assignee\s+(?:contains|includes|in|is|equals?|has)\s+(\w+)',
            r'technician\s+(?:contains|includes|in|is|equals?|has)\s+(\w+)',
            r'assigned\s+to\s+(\w+)',
            r'user\s+(?:is|named|called)\s+(\w+)',
            r'requester\s+(?:is|named|called)\s+(\w+)',
            r'createdby\s+(\w+)',
            r'(?:by|from)\s+(\w+)'
        ]

        for pattern in user_patterns:
            matches = re.findall(pattern, user_prompt.lower())
            for match in matches:
                # Handle special cases first
                if match in ['unassigned', 'none', 'null']:
                    resolved_users[match] = 0  # Map unassigned to ID 0
                    print(f"âœ… Resolved '{match}' to ID: 0 (unassigned)")
                elif match in ['autominds', 'automind']:
                    resolved_users[match] = 0  # Based on test cases, AutoMinds maps to 0
                    print(f"âœ… Resolved '{match}' to ID: 0 (based on test cases)")
                elif user_mapping and match in user_mapping:
                    resolved_users[match] = user_mapping[match]
                    print(f"âœ… Resolved user '{match}' to ID: {user_mapping[match]}")
                elif user_mapping:
                    # Try partial matching
                    partial_matches = {name: uid for name, uid in user_mapping.items()
                                     if match in name}
                    if partial_matches:
                        matched_name, user_id = next(iter(partial_matches.items()))
                        resolved_users[match] = user_id
                        print(f"âœ… Partial match '{match}' -> '{matched_name}' (ID: {user_id})")
                else:
                    # Fallback mapping when API is not available
                    fallback_mapping = {
                        'autominds': 0,
                        'automind': 0,
                        'unassigned': 0
                    }
                    if match in fallback_mapping:
                        resolved_users[match] = fallback_mapping[match]
                        print(f"âœ… Fallback resolved '{match}' to ID: {fallback_mapping[match]}")

        return resolved_users

    def resolve_urgency_references(self, user_prompt: str) -> Dict[str, int]:
        """Resolve urgency names to IDs in the prompt"""
        urgency_mapping = self.get_urgency_mapping()
        resolved_urgencies = {}

        import re

        # Patterns to find urgency references
        urgency_patterns = [
            r'urgency\s+(?:is|as|equals?)\s+(\w+)',
            r'urgency\s+(?:contains|includes)\s+(\w+)',
            r'(\w+)\s+urgency',
            r'priority\s+(?:is|as|equals?)\s+(\w+)'  # Sometimes urgency is called priority
        ]

        for pattern in urgency_patterns:
            matches = re.findall(pattern, user_prompt.lower())
            for match in matches:
                if match in urgency_mapping:
                    resolved_urgencies[match] = urgency_mapping[match]
                    print(f"âœ… Resolved urgency '{match}' to ID: {urgency_mapping[match]}")

        return resolved_urgencies

    def resolve_category_references(self, user_prompt: str) -> Dict[str, Any]:
        """Resolve category names to IDs in the prompt"""
        import re
        import requests

        print(f"ğŸ” Category analysis: '{user_prompt}'")

        # Check if this is ONLY a department query (no explicit category mentioned)
        prompt_lower = user_prompt.lower()

        # Check if category is explicitly mentioned
        category_explicitly_mentioned = bool(re.search(r'\bcategory\s+(?:is|as|equals?)', prompt_lower))

        # Check if department is mentioned
        department_patterns = [
            r'\bdepartment\s+(?:is|equals?|as)\s+',
            r'(?:with|having)\s+department\s+',
            r'requests?\s+(?:with|having|where)\s+department\s+'
        ]

        department_mentioned = any(re.search(pattern, prompt_lower) for pattern in department_patterns)

        # Only skip category resolution if department is mentioned BUT category is NOT explicitly mentioned
        if department_mentioned and not category_explicitly_mentioned:
            print("ğŸš« Department-only query detected - skipping category resolution")
            return {'included': {}, 'excluded': {}, 'operator': 'in'}

        # Step 1: Fetch all available categories from the system
        category_mapping = self._fetch_dynamic_category_mapping()
        if not category_mapping:
            print("âŒ Failed to fetch dynamic category mapping")
            return {'included': {}, 'excluded': {}, 'operator': 'in'}

        print(f"âœ… Fetched {len(category_mapping)} categories from system: {list(category_mapping.keys())}")

        # Step 2: Detect category-related patterns
        category_patterns = [
            r'category\s+(?:is|equals?)\s+([a-z\s]{2,}?)(?:\s|$|,)',
            r'(?:with|having)\s+category\s+(?:is\s+|as\s+)?([a-z\s]{2,}?)(?:\s|$|,)',
            r'category\s+(?:as\s+)?([a-z\s]{2,}?)(?:\s|$|,)',
            r'(?:in|under)\s+([a-z\s]{2,}?)\s+category',
            r'requests?\s+(?:with|having|where)\s+category\s+(?:is\s+|as\s+)?([a-z\s]{2,}?)(?:\s|$|,)',
        ]

        included_categories = {}

        # Step 3: Parse explicit category mentions from patterns
        for pattern in category_patterns:
            matches = re.findall(pattern, prompt_lower)
            for match in matches:
                print(f"ğŸ¯ Found category pattern: '{match}'")
                parsed_categories = self._parse_dynamic_category_list(match, category_mapping)
                included_categories.update(parsed_categories)

        # Step 4: Scan for direct category name mentions
        for category_name, category_id in category_mapping.items():
            if category_name in prompt_lower:
                included_categories[category_name] = category_id
                print(f"âœ… Direct category match: '{category_name}' -> ID {category_id}")

        # Step 4.5: Try common term mappings if no direct matches found
        if not included_categories:
            common_mappings = {
                'it': 'software',  # Map IT to software category
                'tech': 'software',
                'technology': 'software'
            }

            for common_term, mapped_category in common_mappings.items():
                if common_term in prompt_lower and mapped_category in category_mapping:
                    category_id = category_mapping[mapped_category]
                    included_categories[mapped_category] = category_id
                    print(f"âœ… Common term mapping: '{common_term}' -> '{mapped_category}' -> ID {category_id}")
                    break

        # Step 5: Return result
        result = {
            'included': included_categories,
            'excluded': {},  # Categories typically don't have exclusion patterns
            'operator': 'in'
        }

        print(f"ğŸ¯ Category resolution result: {result}")
        return result

    def _fetch_dynamic_category_mapping(self) -> Dict[str, int]:
        """Fetch all available categories from the system dynamically"""
        import requests
        import json

        try:
            print("ğŸ”„ Fetching dynamic category mapping from API...")

            # API endpoint for category search
            url = "https://172.16.15.113/api/request/category"

            # Get fresh access token
            access_token = self.get_access_token()
            if not access_token:
                print("âŒ Cannot fetch category mapping - no access token")
                return {}

            # Headers with fresh token
            headers = {
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',
                'Authorization': f'Bearer {access_token}',
                'Connection': 'keep-alive',
                'Content-Type': 'application/json',
                'Referer': 'https://172.16.15.113/admin/category/?type=request',
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'
            }

            # Make the API call (GET request for categories)
            response = requests.get(url, headers=headers, verify=False, timeout=10)

            if response.status_code == 200:
                data = response.json()
                print(f"âœ… Category API response received: {response.status_code}")

                # Parse the response to extract category name -> ID mapping
                category_mapping = {}

                # Handle hierarchical category structure
                if isinstance(data, list):
                    print(f"   ğŸ“‚ Found list with {len(data)} category trees")

                    # Extract categories from hierarchical structure
                    def extract_categories_recursive(category_tree):
                        """Recursively extract categories from nested structure"""
                        categories = []

                        if isinstance(category_tree, dict) and 'node' in category_tree:
                            # Extract the main category node
                            node = category_tree['node']
                            if isinstance(node, dict) and 'name' in node and 'id' in node:
                                categories.append(node)

                            # Extract child categories
                            children = category_tree.get('childrens', [])
                            if children:
                                for child in children:
                                    categories.extend(extract_categories_recursive(child))

                        return categories

                    # Extract all categories from the tree structure
                    all_categories = []
                    for tree in data:
                        all_categories.extend(extract_categories_recursive(tree))

                    print(f"   ğŸ“‚ Extracted {len(all_categories)} total categories from hierarchy")

                    # Build category mapping
                    for category in all_categories:
                        if isinstance(category, dict) and 'name' in category and 'id' in category:
                            category_id = category['id']
                            category_name = category['name'].lower().strip()
                            category_mapping[category_name] = category_id
                            print(f"   ğŸ“‚ Mapped: '{category_name}' -> ID {category_id}")

                else:
                    print(f"âŒ Unexpected response format: {type(data)}")
                    return {}

                print(f"âœ… Dynamic category mapping loaded: {len(category_mapping)} categories")
                return category_mapping

            else:
                print(f"âŒ Category API call failed: {response.status_code}")
                print(f"   Response: {response.text[:200]}...")
                return {}

        except requests.exceptions.RequestException as e:
            print(f"âŒ Network error fetching category mapping: {str(e)}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ JSON decode error: {str(e)}")
            return {}
        except Exception as e:
            print(f"âŒ Unexpected error fetching category mapping: {str(e)}")
            return {}

    def _parse_dynamic_category_list(self, category_text: str, category_mapping: Dict[str, int]) -> Dict[str, int]:
        """Parse category list using dynamic category mapping with intelligent matching"""
        import re

        parsed_categories = {}

        print(f"ğŸ” Parsing category text: '{category_text}' against {len(category_mapping)} available categories")

        # Split by various separators
        separators = [',', ' and ', ' or ', '&', '+', ';']
        parts = [category_text.strip()]

        for sep in separators:
            new_parts = []
            for part in parts:
                new_parts.extend([p.strip() for p in part.split(sep)])
            parts = new_parts

        # Clean and resolve each part
        for part in parts:
            part = re.sub(r'[^\w\s]', '', part).strip()  # Remove punctuation
            if not part or len(part) < 2:  # Skip empty or single character parts
                continue

            print(f"   ğŸ” Analyzing part: '{part}' (length: {len(part)})")

            # Try exact match first (case-insensitive)
            part_lower = part.lower()
            if part_lower in category_mapping:
                parsed_categories[part_lower] = category_mapping[part_lower]
                print(f"   âœ… Exact match: '{part}' -> '{part_lower}' -> ID {category_mapping[part_lower]}")
                continue

            # Try partial matching with intelligent scoring (allow shorter matches for categories like "IT")
            if len(part) >= 2:  # Allow 2-character matches for categories like "IT"
                best_matches = []
                for category_name, category_id in category_mapping.items():
                    score = self._calculate_category_match_score(part_lower, category_name)
                    # Use different thresholds based on length
                    threshold = 0.9 if len(part) == 2 else 0.7
                    if score > threshold:
                        best_matches.append((category_name, category_id, score))

                # Sort by score and take the best match
                if best_matches:
                    best_matches.sort(key=lambda x: x[2], reverse=True)
                    best_category, best_id, best_score = best_matches[0]
                    parsed_categories[best_category] = best_id
                    print(f"   âœ… Partial match: '{part}' -> '{best_category}' -> ID {best_id} (score: {best_score:.2f})")
                else:
                    print(f"   âŒ No match found for: '{part}' (no valid partial matches)")
            else:
                print(f"   âŒ Skipping: '{part}' (too short for partial matching)")

        print(f"ğŸ¯ Parsed {len(parsed_categories)} categories: {list(parsed_categories.keys())}")
        return parsed_categories

    def _calculate_category_match_score(self, search_term: str, category_name: str) -> float:
        """Calculate matching score between search term and category name"""

        # Exact match
        if search_term == category_name:
            return 1.0

        # Contains match
        if search_term in category_name or category_name in search_term:
            return 0.8

        # Word-based matching
        search_words = set(search_term.split())
        category_words = set(category_name.split())

        if search_words & category_words:  # Common words
            overlap = len(search_words & category_words)
            total = len(search_words | category_words)
            return 0.6 + (overlap / total) * 0.2

        # Character similarity (simple)
        common_chars = set(search_term) & set(category_name)
        if common_chars:
            return len(common_chars) / max(len(search_term), len(category_name)) * 0.4

        return 0.0

    def resolve_department_references(self, user_prompt: str) -> Dict[str, Any]:
        """Resolve department names to IDs in the prompt"""
        import re
        import requests

        print(f"ğŸ” Department analysis: '{user_prompt}'")

        # Step 1: Fetch all available departments from the system
        department_mapping = self._fetch_dynamic_department_mapping()
        if not department_mapping:
            print("âŒ Failed to fetch dynamic department mapping")
            return {'included': {}, 'excluded': {}, 'operator': 'in'}

        print(f"âœ… Fetched {len(department_mapping)} departments from system: {list(department_mapping.keys())}")

        # Step 2: Detect department-related patterns (enhanced for multiple departments)
        department_patterns = [
            r'department\s+(?:is|equals?)\s+(.+?)(?:\s*$)',
            r'(?:with|having)\s+department\s+(?:is\s+|as\s+)?(.+?)(?:\s*$)',
            r'requests?\s+(?:with|having|where)\s+department\s+(?:is\s+|as\s+)?(.+?)(?:\s*$)',
        ]

        included_departments = {}
        prompt_lower = user_prompt.lower()

        # Step 3: Parse explicit department mentions from patterns
        for pattern in department_patterns:
            matches = re.findall(pattern, prompt_lower)
            for match in matches:
                print(f"ğŸ¯ Found department pattern: '{match}' from pattern: {pattern}")
                parsed_departments = self._parse_dynamic_department_list(match, department_mapping)
                included_departments.update(parsed_departments)

        # Step 4: Scan for direct department name mentions (only if no pattern matches found)
        if not included_departments:
            for department_name, department_id in department_mapping.items():
                # Use word boundaries to ensure exact word matches
                if re.search(r'\b' + re.escape(department_name) + r'\b', prompt_lower):
                    included_departments[department_name] = department_id
                    print(f"âœ… Direct department match: '{department_name}' -> ID {department_id}")
                    # Continue to find all matching departments

        # Step 5: Return result
        result = {
            'included': included_departments,
            'excluded': {},  # Departments typically don't have exclusion patterns
            'operator': 'in'
        }

        print(f"ğŸ¯ Department resolution result: {result}")
        return result

    def _fetch_dynamic_department_mapping(self) -> Dict[str, int]:
        """Fetch all available departments from the system dynamically"""
        import requests
        import json

        try:
            print("ğŸ”„ Fetching dynamic department mapping from API...")

            # API endpoint for department search
            url = "https://172.16.15.113/api/department"

            # Get fresh access token
            access_token = self.get_access_token()
            if not access_token:
                print("âŒ Cannot fetch department mapping - no access token")
                return {}

            # Headers with fresh token
            headers = {
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',
                'Authorization': f'Bearer {access_token}',
                'Connection': 'keep-alive',
                'Content-Type': 'application/json',
                'Referer': 'https://172.16.15.113/admin/organization/department',
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'
            }

            # Make the API call (GET request for departments)
            response = requests.get(url, headers=headers, verify=False, timeout=10)

            if response.status_code == 200:
                data = response.json()
                print(f"âœ… Department API response received: {response.status_code}")

                # Parse the response to extract department name -> ID mapping
                department_mapping = {}

                # Handle hierarchical department structure (similar to categories)
                if isinstance(data, list):
                    print(f"   ğŸ¢ Found list with {len(data)} department trees")

                    # Extract departments from hierarchical structure
                    def extract_departments_recursive(department_tree):
                        """Recursively extract departments from nested structure"""
                        departments = []

                        if isinstance(department_tree, dict) and 'node' in department_tree:
                            # Extract the main department node
                            node = department_tree['node']
                            if isinstance(node, dict) and 'name' in node and 'id' in node:
                                departments.append(node)

                            # Extract child departments
                            children = department_tree.get('childrens', [])
                            if children:
                                for child in children:
                                    departments.extend(extract_departments_recursive(child))

                        return departments

                    # Extract all departments from the tree structure
                    all_departments = []
                    for tree in data:
                        all_departments.extend(extract_departments_recursive(tree))

                    print(f"   ğŸ¢ Extracted {len(all_departments)} total departments from hierarchy")

                    # Build department mapping
                    for department in all_departments:
                        if isinstance(department, dict) and 'name' in department and 'id' in department:
                            department_id = department['id']
                            department_name = department['name'].lower().strip()
                            department_mapping[department_name] = department_id
                            print(f"   ğŸ¢ Mapped: '{department_name}' -> ID {department_id}")

                else:
                    print(f"âŒ Unexpected response format: {type(data)}")
                    return {}

                print(f"âœ… Dynamic department mapping loaded: {len(department_mapping)} departments")
                return department_mapping

            else:
                print(f"âŒ Department API call failed: {response.status_code}")
                print(f"   Response: {response.text[:200]}...")
                return {}

        except requests.exceptions.RequestException as e:
            print(f"âŒ Network error fetching department mapping: {str(e)}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ JSON decode error: {str(e)}")
            return {}
        except Exception as e:
            print(f"âŒ Unexpected error fetching department mapping: {str(e)}")
            return {}

    def _parse_dynamic_department_list(self, department_text: str, department_mapping: Dict[str, int]) -> Dict[str, int]:
        """Parse department list using dynamic department mapping with intelligent matching"""
        import re

        parsed_departments = {}

        print(f"ğŸ” Parsing department text: '{department_text}' against {len(department_mapping)} available departments")

        # Split by various separators (enhanced for better parsing)
        separators = [',', ' and ', ' or ', '&', '+', ';', ' ']
        parts = [department_text.strip()]

        # Apply separators iteratively to split the text
        for sep in separators:
            new_parts = []
            for part in parts:
                if sep in part:
                    split_parts = [p.strip() for p in part.split(sep) if p.strip()]
                    new_parts.extend(split_parts)
                else:
                    new_parts.append(part)
            parts = new_parts

        # Remove duplicates while preserving order
        unique_parts = []
        for part in parts:
            if part not in unique_parts:
                unique_parts.append(part)
        parts = unique_parts

        print(f"   ğŸ” Split into parts: {parts}")

        # Clean and resolve each part
        for part in parts:
            part = re.sub(r'[^\w\s]', '', part).strip()  # Remove punctuation
            if not part or len(part) < 2:  # Skip empty or single character parts
                continue

            print(f"   ğŸ” Analyzing part: '{part}' (length: {len(part)})")

            # Try exact match first (case-insensitive)
            part_lower = part.lower()
            if part_lower in department_mapping:
                parsed_departments[part_lower] = department_mapping[part_lower]
                print(f"   âœ… Exact match: '{part}' -> '{part_lower}' -> ID {department_mapping[part_lower]}")
                # Continue processing other parts for multiple departments
                continue

            # Try partial matching with intelligent scoring (only if no exact match found)
            if len(part) >= 2:  # Allow shorter matches for departments like "IT"
                best_matches = []
                for department_name, department_id in department_mapping.items():
                    # Skip if we already found this department
                    if department_name in parsed_departments:
                        continue
                    score = self._calculate_department_match_score(part_lower, department_name)
                    if score > 0.9:  # Much higher threshold for partial matching to avoid false positives
                        best_matches.append((department_name, department_id, score))

                # Sort by score and take the best match
                if best_matches:
                    best_matches.sort(key=lambda x: x[2], reverse=True)
                    best_department, best_id, best_score = best_matches[0]
                    parsed_departments[best_department] = best_id
                    print(f"   âœ… Partial match: '{part}' -> '{best_department}' -> ID {best_id} (score: {best_score:.2f})")
                else:
                    print(f"   âŒ No match found for: '{part}' (no valid partial matches)")
            else:
                print(f"   âŒ Skipping: '{part}' (too short for partial matching)")

        print(f"ğŸ¯ Parsed {len(parsed_departments)} departments: {list(parsed_departments.keys())}")
        return parsed_departments

    def _calculate_department_match_score(self, search_term: str, department_name: str) -> float:
        """Calculate matching score between search term and department name"""

        # Exact match
        if search_term == department_name:
            return 1.0

        # Contains match
        if search_term in department_name or department_name in search_term:
            return 0.8

        # Word-based matching
        search_words = set(search_term.split())
        department_words = set(department_name.split())

        if search_words & department_words:  # Common words
            overlap = len(search_words & department_words)
            total = len(search_words | department_words)
            return 0.6 + (overlap / total) * 0.2

        # Character similarity (simple)
        common_chars = set(search_term) & set(department_name)
        if common_chars:
            return len(common_chars) / max(len(search_term), len(department_name)) * 0.4

        return 0.0

    def resolve_subject_references(self, user_prompt: str) -> Dict[str, Any]:
        """Resolve subject contains/equals patterns"""
        import re

        print(f"ğŸ” Subject analysis: '{user_prompt}'")

        # Subject patterns
        subject_patterns = [
            r'subject\s+contains\s+([a-z\s]+?)(?:\s+and\s+(?!subject)|$)',
            r'subject\s+(?:is|equals?)\s+([a-z\s]+?)(?:\s+and\s+(?!subject)|$)',
            r'(?:with|having)\s+subject\s+(?:contains|is|equals?)\s+([a-z\s]+?)(?:\s+and\s+(?!subject)|$)',
        ]

        subject_filters = []
        prompt_lower = user_prompt.lower()
        seen_subjects = set()  # Track seen subjects to avoid duplicates

        for pattern in subject_patterns:
            matches = re.findall(pattern, prompt_lower)
            for match in matches:
                subject_text = match.strip()
                if subject_text and subject_text not in seen_subjects:
                    print(f"ğŸ¯ Found subject pattern: '{subject_text}'")

                    # Determine operator based on pattern
                    if 'contains' in pattern:
                        operator = 'contains'
                    else:
                        operator = 'equal'

                    subject_filters.append({
                        'text': subject_text,
                        'operator': operator
                    })
                    seen_subjects.add(subject_text)

        result = {
            'filters': subject_filters
        }

        print(f"ğŸ¯ Subject resolution result: {result}")
        return result

    def resolve_status_references(self, user_prompt: str) -> Dict[str, Any]:
        """Dynamic status resolution using live API data - NO STATIC MAPPINGS"""
        import re
        import requests

        print(f"ğŸ” Dynamic status analysis: '{user_prompt}'")

        # Step 1: Fetch all available statuses from the system
        status_mapping = self._fetch_dynamic_status_mapping()
        if not status_mapping:
            print("âŒ Failed to fetch dynamic status mapping")
            return {'included': {}, 'excluded': {}, 'operator': 'in'}

        print(f"âœ… Fetched {len(status_mapping)} statuses from system: {list(status_mapping.keys())}")

        # Step 2: Detect exclusion patterns first
        exclusion_patterns = [
            r'(?:not|except|excluding|without)\s+(?:status\s+)?(?:is\s+)?([a-z\s,]+?)(?:\s|$)',
            r'status\s+(?:is\s+)?(?:not|except|excluding)\s+([a-z\s,]+?)(?:\s|$)',
            r'(?:all|show|get)\s+(?:requests?|tickets?)\s+(?:not|except|excluding)\s+([a-z\s,]+?)(?:\s|$)'
        ]

        excluded_statuses = {}
        for pattern in exclusion_patterns:
            matches = re.findall(pattern, user_prompt.lower())
            for match in matches:
                print(f"ğŸš« Found exclusion pattern: '{match}'")
                excluded_parts = self._parse_dynamic_status_list(match, status_mapping)
                excluded_statuses.update(excluded_parts)

        # Step 3: Enhanced inclusion patterns for detecting multiple statuses - FIXED TO AVOID SINGLE CHARACTERS
        inclusion_patterns = [
            # Multiple separate "status is X" clauses - PRIORITY PATTERN
            r'status\s+(?:is|are|equals?)\s+([a-z\s]{2,}?)(?=\s+and\s+status|\s+or\s+status|$)',
            # Complex multi-status patterns with conjunctions - MINIMUM 2 CHARACTERS
            r'status\s+(?:is|are|in|includes?)\s+([a-z\s,]{3,}?)(?:\s+(?:and|or)\s+[a-z\s,]{3,}?)*',
            r'(?:with|having)\s+status\s+([a-z\s,]{3,}?)(?:\s+(?:and|or)\s+[a-z\s,]{3,}?)*',
            r'(?:where|when)\s+status\s+(?:is|are|in)\s+([a-z\s,]{3,}?)(?:\s+(?:and|or)\s+[a-z\s,]{3,}?)*',
            # Comma-separated status lists - MINIMUM 3 CHARACTERS
            r'status\s+(?:is|are|in)\s+([a-z\s,]{3,}(?:,\s*[a-z\s]{2,})*)',
            # Multiple status mentions in same sentence - MINIMUM 3 CHARACTERS
            r'(?:requests?|tickets?)\s+(?:with|having|where)\s+status\s+([a-z\s,]{3,})',
        ]

        included_statuses = {}

        # Step 3.1: Handle multiple "status is X" clauses first (highest priority)
        multiple_status_clauses = self._find_multiple_status_clauses(user_prompt, status_mapping)
        if multiple_status_clauses:
            print(f"ğŸ¯ Found multiple status clauses: {list(multiple_status_clauses.keys())}")
            included_statuses.update(multiple_status_clauses)

        # Step 3.2: Scan entire prompt for individual status mentions
        all_status_mentions = self._find_all_status_mentions(user_prompt, status_mapping)
        if all_status_mentions:
            print(f"ğŸ¯ Found individual status mentions: {list(all_status_mentions.keys())}")
            included_statuses.update(all_status_mentions)

        # Step 4: Handle business logic shortcuts using dynamic mapping
        prompt_lower = user_prompt.lower()
        if any(term in prompt_lower for term in ['active', 'working']) and 'request' in prompt_lower:
            # Find open and in progress statuses dynamically
            for status_name, status_id in status_mapping.items():
                if 'open' in status_name.lower() or 'progress' in status_name.lower():
                    included_statuses[status_name] = status_id
            print(f"ğŸ¯ Business logic: Active requests = {list(included_statuses.keys())}")
        elif any(term in prompt_lower for term in ['unresolved']) and 'request' in prompt_lower:
            # Find all non-closed statuses
            for status_name, status_id in status_mapping.items():
                if not any(term in status_name.lower() for term in ['closed', 'resolved', 'cancelled']):
                    included_statuses[status_name] = status_id
            print(f"ğŸ¯ Business logic: Unresolved = {list(included_statuses.keys())}")
        elif any(term in prompt_lower for term in ['completed', 'finished']) and 'request' in prompt_lower:
            # Find resolved and closed statuses
            for status_name, status_id in status_mapping.items():
                if any(term in status_name.lower() for term in ['resolved', 'closed']):
                    included_statuses[status_name] = status_id
            print(f"ğŸ¯ Business logic: Completed = {list(included_statuses.keys())}")

        # Step 5: Parse explicit status mentions from patterns
        for pattern in inclusion_patterns:
            matches = re.findall(pattern, prompt_lower)
            for match in matches:
                print(f"ğŸ¯ Found inclusion pattern: '{match}'")
                parsed_statuses = self._parse_dynamic_status_list(match, status_mapping)
                included_statuses.update(parsed_statuses)

        # Step 6: Ensure we have at least 2 statuses if multiple are detected
        if len(included_statuses) > 1:
            print(f"ğŸ¯ Multiple statuses detected ({len(included_statuses)}): {list(included_statuses.keys())}")
            # Keep all detected statuses for multi-value filtering
        elif len(included_statuses) == 1:
            print(f"ğŸ¯ Single status detected: {list(included_statuses.keys())}")
        else:
            print("ğŸ” No explicit statuses detected, checking for implicit patterns...")
            # Only add implicit status patterns if the query is actually about status
            if self._is_status_related_query(user_prompt):
                implicit_statuses = self._detect_implicit_status_patterns(user_prompt, status_mapping)
                included_statuses.update(implicit_statuses)
            else:
                print("ğŸ” Query is not status-related, skipping implicit status patterns")

        # Step 7: Clean up and prioritize explicit mentions over pattern matches
        final_included_statuses = self._prioritize_explicit_status_mentions(user_prompt, included_statuses, status_mapping)

        # Step 8: Return result with operator information
        result = {
            'included': final_included_statuses,
            'excluded': excluded_statuses,
            'operator': 'not_in' if excluded_statuses and not final_included_statuses else 'in'
        }

        print(f"ğŸ¯ Dynamic status resolution result: {result}")
        return result

    def _fetch_dynamic_status_mapping(self) -> Dict[str, int]:
        """Fetch all available statuses from the system dynamically"""
        import requests
        import json

        try:
            print("ğŸ”„ Fetching dynamic status mapping from API...")

            # API endpoint for status search
            url = "https://172.16.15.113/api/request/status/search/byqual"

            # Headers from the provided curl command
            headers = {
                'Accept': 'application/json, text/plain, */*',
                'Accept-Language': 'en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7',
                'Authorization': 'Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJsb2dpbl9zc29faWQiOjAsInVzZXJfbmFtZSI6InV1aWQzNi04OWRiOTc1My0zYTA5LTQzYTgtYTIzYS03ZjMwOGJkNDIyMWEiLCJzY29wZSI6WyJOTy1TQ09QRSJdLCJsb2dpbl9zb3VyY2UiOiJub3JtYWxfbG9naW4iLCJleHAiOjE3NTQyMjIwODgsImxvZ2luX21zcF9wb3J0YWxfaWQiOjAsImp0aSI6IjBlZTg5ZDhlLWRmMmEtNDdmNi04MTNmLTRlNDNmOWNjNDhjZiIsImNsaWVudF9pZCI6ImZsb3RvLXdlYi1hcHAiLCJ0ZW5hbnRJZGVudGlmaWVyIjoiYXBvbG8ifQ.rPoMP1NzWZqdTOdRQcOY5vvxwos2DRQPjYybhMaQOze9zXXJRhCXWOU5NoRTH8DmVtHxC6ouBZ-zNQ0yqOGItrl2cSS1VJcyzOnRLyVcNL4xVPttrAvo3anycKrinp3lHQDCysNg6UZ9tgjrCstDf7kmnotMXjU0eDiSBYbzSxt69dQCLlLVECS4Trescg1XZu1Hw7qO8WYxqN9gJML80BQSfylaZAxcWoEEWI9O1GQ8BClNxH1wUEdDGsBBDCrqI1ZtFera1WnYC99fnHDeQSYWPzArYsb7J8T27UQfuHDhFJy8iF3g0bJqoo2dxZb6eg3txnBKL-dTVznSrwVNsA',
                'Connection': 'keep-alive',
                'Content-Type': 'application/json',
                'Origin': 'https://172.16.15.113',
                'Referer': 'https://172.16.15.113/admin/status/?type=request',
                'Sec-Fetch-Dest': 'empty',
                'Sec-Fetch-Mode': 'cors',
                'Sec-Fetch-Site': 'same-origin',
                'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36',
                'sec-ch-ua': '"Chromium";v="136", "Google Chrome";v="136", "Not.A/Brand";v="99"',
                'sec-ch-ua-mobile': '?0',
                'sec-ch-ua-platform': '"Linux"'
            }

            # Empty request body as per curl command
            payload = {}

            # Make the API call
            response = requests.post(url, headers=headers, json=payload, verify=False, timeout=10)

            if response.status_code == 200:
                data = response.json()
                print(f"âœ… Status API response received: {response.status_code}")

                # Parse the response to extract status name -> ID mapping
                status_mapping = {}

                # Handle different possible response structures
                if isinstance(data, dict):
                    # Check for 'objectList' field (status API specific)
                    if 'objectList' in data:
                        statuses = data['objectList']
                        print(f"   ğŸ“‹ Found objectList with {len(statuses)} statuses")
                    # Check for 'content' field (common in paginated responses)
                    elif 'content' in data:
                        statuses = data['content']
                    # Check for 'data' field
                    elif 'data' in data:
                        statuses = data['data']
                    # Check if data itself is the status list
                    elif 'id' in data and 'name' in data:
                        statuses = [data]
                    else:
                        print(f"   ğŸ” Checking all keys in response: {list(data.keys())}")
                        statuses = data
                elif isinstance(data, list):
                    statuses = data
                else:
                    print(f"âŒ Unexpected response format: {type(data)}")
                    return {}

                # Extract status mappings
                for status in statuses:
                    if isinstance(status, dict) and 'id' in status and 'name' in status:
                        status_id = status['id']
                        status_name = status['name'].lower().strip()
                        status_mapping[status_name] = status_id
                        print(f"   ğŸ“‹ Mapped: '{status_name}' -> ID {status_id}")

                print(f"âœ… Dynamic status mapping loaded: {len(status_mapping)} statuses")
                return status_mapping

            else:
                print(f"âŒ Status API call failed: {response.status_code}")
                print(f"   Response: {response.text[:200]}...")
                return {}

        except requests.exceptions.RequestException as e:
            print(f"âŒ Network error fetching status mapping: {str(e)}")
            return {}
        except json.JSONDecodeError as e:
            print(f"âŒ JSON decode error: {str(e)}")
            return {}
        except Exception as e:
            print(f"âŒ Unexpected error fetching status mapping: {str(e)}")
            return {}

    def _parse_dynamic_status_list(self, status_text: str, status_mapping: Dict[str, int]) -> Dict[str, int]:
        """Parse status list using dynamic status mapping with intelligent matching"""
        import re

        parsed_statuses = {}

        print(f"ğŸ” Parsing status text: '{status_text}' against {len(status_mapping)} available statuses")

        # Split by various separators
        separators = [',', ' and ', ' or ', '&', '+', ';']
        parts = [status_text.strip()]

        for sep in separators:
            new_parts = []
            for part in parts:
                new_parts.extend([p.strip() for p in part.split(sep)])
            parts = new_parts

        # Clean and resolve each part
        for part in parts:
            part = re.sub(r'[^\w\s]', '', part).strip()  # Remove punctuation
            if not part or len(part) < 2:  # Skip empty or single character parts
                continue

            print(f"   ğŸ” Analyzing part: '{part}' (length: {len(part)})")

            # Try exact match first (case-insensitive)
            part_lower = part.lower()
            if part_lower in status_mapping:
                parsed_statuses[part_lower] = status_mapping[part_lower]
                print(f"   âœ… Exact match: '{part}' -> '{part_lower}' -> ID {status_mapping[part_lower]}")
                continue

            # Try partial matching with intelligent scoring - ONLY for parts with 3+ characters
            if len(part) >= 3:
                best_matches = []
                for status_name, status_id in status_mapping.items():
                    score = self._calculate_status_match_score(part_lower, status_name)
                    if score > 0.7:  # Higher threshold for partial matching
                        best_matches.append((status_name, status_id, score))

                # Sort by score and take the best match
                if best_matches:
                    best_matches.sort(key=lambda x: x[2], reverse=True)
                    best_status, best_id, best_score = best_matches[0]
                    parsed_statuses[best_status] = best_id
                    print(f"   âœ… Partial match: '{part}' -> '{best_status}' -> ID {best_id} (score: {best_score:.2f})")
                else:
                    print(f"   âŒ No match found for: '{part}' (no valid partial matches)")
            else:
                print(f"   âŒ Skipping: '{part}' (too short for partial matching)")

        print(f"ğŸ¯ Parsed {len(parsed_statuses)} statuses: {list(parsed_statuses.keys())}")
        return parsed_statuses

    def _calculate_status_match_score(self, search_term: str, status_name: str) -> float:
        """Calculate matching score between search term and status name"""

        # Exact match
        if search_term == status_name:
            return 1.0

        # Contains match
        if search_term in status_name or status_name in search_term:
            return 0.8

        # Word-based matching
        search_words = set(search_term.split())
        status_words = set(status_name.split())

        if search_words & status_words:  # Common words
            overlap = len(search_words & status_words)
            total = len(search_words | status_words)
            return 0.6 + (overlap / total) * 0.2

        # Character similarity (simple)
        common_chars = set(search_term) & set(status_name)
        if common_chars:
            return len(common_chars) / max(len(search_term), len(status_name)) * 0.4

        return 0.0

    def _find_all_status_mentions(self, user_prompt: str, status_mapping: Dict[str, int]) -> Dict[str, int]:
        """Find all status mentions in the prompt using comprehensive scanning"""
        import re

        found_statuses = {}
        prompt_lower = user_prompt.lower()

        print(f"ğŸ” Scanning entire prompt for status mentions...")

        # Method 1: Direct status name matching
        for status_name, status_id in status_mapping.items():
            # Try exact phrase matching
            if status_name in prompt_lower:
                found_statuses[status_name] = status_id
                print(f"   âœ… Direct match: '{status_name}' -> ID {status_id}")
                continue

            # Try word-boundary matching for multi-word statuses
            status_words = status_name.split()
            if len(status_words) > 1:
                # Check if all words of the status appear in sequence
                pattern = r'\b' + r'\s+'.join(re.escape(word) for word in status_words) + r'\b'
                if re.search(pattern, prompt_lower):
                    found_statuses[status_name] = status_id
                    print(f"   âœ… Multi-word match: '{status_name}' -> ID {status_id}")
                    continue

            # Try partial word matching for single words
            if len(status_words) == 1:
                word = status_words[0]
                if len(word) > 3:  # Only for longer words to avoid false positives
                    pattern = r'\b' + re.escape(word) + r'\b'
                    if re.search(pattern, prompt_lower):
                        found_statuses[status_name] = status_id
                        print(f"   âœ… Word match: '{status_name}' -> ID {status_id}")

        # Method 2: Common status variations and synonyms
        status_variations = {
            'open': ['opened', 'new', 'active'],
            'closed': ['close', 'completed', 'done', 'finished'],
            'pending': ['waiting', 'hold', 'on hold'],
            'resolved': ['fixed', 'solved', 'complete'],
            'in progress': ['progress', 'working', 'ongoing', 'processing'],
            'testing': ['test', 'qa', 'verification'],
            'cancelled': ['canceled', 'abort', 'aborted'],
            'rejected': ['reject', 'denied', 'declined']
        }

        for base_status, variations in status_variations.items():
            # Find the actual status name in our mapping that matches the base
            matching_status = None
            for status_name in status_mapping.keys():
                if base_status in status_name or any(var in status_name for var in variations):
                    matching_status = status_name
                    break

            if matching_status and matching_status not in found_statuses:
                # Check if any variation appears in the prompt
                for variation in variations:
                    pattern = r'\b' + re.escape(variation) + r'\b'
                    if re.search(pattern, prompt_lower):
                        found_statuses[matching_status] = status_mapping[matching_status]
                        print(f"   âœ… Variation match: '{variation}' -> '{matching_status}' -> ID {status_mapping[matching_status]}")
                        break

        print(f"ğŸ¯ Total status mentions found: {len(found_statuses)}")
        return found_statuses

    def _find_multiple_status_clauses(self, user_prompt: str, status_mapping: Dict[str, int]) -> Dict[str, int]:
        """Find multiple 'status is X' clauses in the same prompt"""
        import re

        found_statuses = {}
        prompt_lower = user_prompt.lower()

        print(f"ğŸ” Scanning for multiple status clauses in: '{user_prompt}'")

        # Pattern to find all "status is X" clauses
        status_clause_pattern = r'status\s+(?:is|are|equals?)\s+([a-z\s]+?)(?=\s+and\s+|$|\s+or\s+)'

        matches = re.findall(status_clause_pattern, prompt_lower)
        print(f"   ğŸ“‹ Found {len(matches)} status clauses: {matches}")

        for match in matches:
            status_term = match.strip()
            print(f"   ğŸ” Processing status clause: '{status_term}'")

            # Try to match against available statuses
            matched_status = None
            matched_id = None

            # Direct exact match
            if status_term in status_mapping:
                matched_status = status_term
                matched_id = status_mapping[status_term]
                print(f"   âœ… Exact match: '{status_term}' -> ID {matched_id}")
            else:
                # Partial matching with scoring
                best_score = 0
                for status_name, status_id in status_mapping.items():
                    score = self._calculate_status_match_score(status_term, status_name)
                    if score > best_score and score > 0.5:  # Threshold for matching
                        best_score = score
                        matched_status = status_name
                        matched_id = status_id

                if matched_status:
                    print(f"   âœ… Partial match: '{status_term}' -> '{matched_status}' -> ID {matched_id} (score: {best_score:.2f})")
                else:
                    print(f"   âŒ No match found for: '{status_term}' (might be priority/other field)")

            # Add to results if matched
            if matched_status and matched_id:
                found_statuses[matched_status] = matched_id

        print(f"ğŸ¯ Multiple status clauses found: {len(found_statuses)} - {list(found_statuses.keys())}")
        return found_statuses

    def _detect_implicit_status_patterns(self, user_prompt: str, status_mapping: Dict[str, int]) -> Dict[str, int]:
        """Detect implicit status patterns when no explicit statuses are found"""
        import re

        implicit_statuses = {}
        prompt_lower = user_prompt.lower()

        print(f"ğŸ” Detecting implicit status patterns...")

        # Pattern 1: Time-based implications
        if any(term in prompt_lower for term in ['recent', 'new', 'latest', 'today', 'yesterday']):
            # Look for "open" or "new" statuses
            for status_name, status_id in status_mapping.items():
                if any(term in status_name.lower() for term in ['open', 'new']):
                    implicit_statuses[status_name] = status_id
                    print(f"   âœ… Time-based implication: '{status_name}' -> ID {status_id}")
                    break

        # Pattern 2: Action-based implications
        if any(term in prompt_lower for term in ['fix', 'solve', 'work on', 'assign']):
            # Look for "open" or "in progress" statuses
            for status_name, status_id in status_mapping.items():
                if any(term in status_name.lower() for term in ['open', 'progress']):
                    implicit_statuses[status_name] = status_id
                    print(f"   âœ… Action-based implication: '{status_name}' -> ID {status_id}")

        # Pattern 3: Completion-based implications
        if any(term in prompt_lower for term in ['done', 'complete', 'finish', 'close']):
            # Look for "resolved" or "closed" statuses
            for status_name, status_id in status_mapping.items():
                if any(term in status_name.lower() for term in ['resolved', 'closed', 'complete']):
                    implicit_statuses[status_name] = status_id
                    print(f"   âœ… Completion-based implication: '{status_name}' -> ID {status_id}")

        # Pattern 4: Default fallback - if no specific patterns, include common active statuses
        if not implicit_statuses and not any(term in prompt_lower for term in ['all', 'every', 'any']):
            print("   ğŸ”„ No implicit patterns found, using default active statuses...")
            for status_name, status_id in status_mapping.items():
                if any(term in status_name.lower() for term in ['open', 'progress']):
                    implicit_statuses[status_name] = status_id
                    print(f"   âœ… Default active status: '{status_name}' -> ID {status_id}")

        print(f"ğŸ¯ Implicit status patterns found: {len(implicit_statuses)}")
        return implicit_statuses

    def _is_status_related_query(self, user_prompt: str) -> bool:
        """Check if the query is actually about status field"""
        import re

        prompt_lower = user_prompt.lower()

        # Check for explicit status mentions
        status_keywords = [
            r'\bstatus\s+(?:is|are|in|equals?)',
            r'(?:with|having)\s+status',
            r'(?:where|when)\s+status',
            r'\bstatus\s*[:=]'
        ]

        for pattern in status_keywords:
            if re.search(pattern, prompt_lower):
                print(f"ğŸ¯ Status-related query detected: pattern '{pattern}' matched")
                return True

        # Check for other field mentions that would indicate this is NOT a status query
        other_field_patterns = [
            r'\bpriority\s+(?:is|are|in|equals?)',
            r'\burgency\s+(?:is|are|in|equals?)',
            r'\bcategory\s+(?:is|are|in|equals?)',
            r'\bdepartment\s+(?:is|are|in|equals?)',
            r'\bassignee\s+(?:is|are|in|equals?)',
            r'\brequester\s+(?:is|are|in|equals?)'
        ]

        for pattern in other_field_patterns:
            if re.search(pattern, prompt_lower):
                print(f"ğŸ¯ Non-status query detected: pattern '{pattern}' matched")
                return False

        # If no specific field mentioned, consider it potentially status-related
        # (for backward compatibility with general queries)
        print("ğŸ” No specific field detected, considering as potentially status-related")
        return True

    def _prioritize_explicit_status_mentions(self, user_prompt: str, detected_statuses: Dict[str, int], status_mapping: Dict[str, int]) -> Dict[str, int]:
        """Prioritize explicit status mentions and remove spurious matches"""
        import re

        print(f"ğŸ” Prioritizing explicit mentions from: {list(detected_statuses.keys())}")

        # Count explicit mentions of each status in the prompt
        explicit_mentions = {}
        prompt_lower = user_prompt.lower()

        for status_name in status_mapping.keys():
            # Count exact word boundary matches
            pattern = r'\b' + re.escape(status_name) + r'\b'
            matches = len(re.findall(pattern, prompt_lower))
            if matches > 0:
                explicit_mentions[status_name] = matches
                print(f"   ğŸ“‹ Explicit mention: '{status_name}' appears {matches} time(s)")

        # If we have explicit mentions, prioritize those
        if explicit_mentions:
            prioritized_statuses = {}
            for status_name, count in explicit_mentions.items():
                if status_name in detected_statuses:
                    prioritized_statuses[status_name] = detected_statuses[status_name]
                    print(f"   âœ… Prioritized: '{status_name}' -> ID {detected_statuses[status_name]}")

            print(f"ğŸ¯ Prioritized {len(prioritized_statuses)} explicit statuses: {list(prioritized_statuses.keys())}")
            return prioritized_statuses

        # If no explicit mentions, return original detected statuses but limit to reasonable count
        if len(detected_statuses) > 5:  # Arbitrary limit to prevent too many spurious matches
            print(f"âš ï¸ Too many detected statuses ({len(detected_statuses)}), limiting to first 3")
            limited_statuses = dict(list(detected_statuses.items())[:3])
            return limited_statuses

        print(f"ğŸ¯ No explicit mentions found, keeping all {len(detected_statuses)} detected statuses")
        return detected_statuses

    def _parse_status_list(self, status_text: str, status_mapping: Dict[str, int]) -> Dict[str, int]:
        """Parse comma-separated or conjunction-separated status list"""
        import re

        parsed_statuses = {}

        # Split by various separators
        separators = [',', ' and ', ' or ', '&', '+']
        parts = [status_text.strip()]

        for sep in separators:
            new_parts = []
            for part in parts:
                new_parts.extend([p.strip() for p in part.split(sep)])
            parts = new_parts

        # Clean and resolve each part
        for part in parts:
            part = re.sub(r'[^\w\s]', '', part).strip()  # Remove punctuation
            if not part or len(part) < 2:  # Skip empty or single character parts
                continue

            # Direct match
            if part in status_mapping:
                parsed_statuses[part] = status_mapping[part]
                print(f"âœ… Parsed status: '{part}' -> {status_mapping[part]}")
            else:
                # Partial match with minimum length requirement
                best_match = None
                best_score = 0
                for status_name, status_id in status_mapping.items():
                    # Only allow partial matching for parts with 3+ characters
                    if len(part) >= 3:
                        if status_name in part or part in status_name:
                            # Calculate a better score
                            if part == status_name:
                                score = 1.0
                            elif part in status_name:
                                score = len(part) / len(status_name)
                            elif status_name in part:
                                score = len(status_name) / len(part)
                            else:
                                score = 0

                            if score > best_score and score > 0.6:  # Higher threshold
                                best_score = score
                                best_match = (status_name, status_id)

                if best_match:
                    status_name, status_id = best_match
                    parsed_statuses[status_name] = status_id
                    print(f"âœ… Partial match: '{part}' -> '{status_name}' -> {status_id} (score: {best_score:.2f})")
                else:
                    print(f"âŒ No valid match for: '{part}' (too short or low score)")

        return parsed_statuses

    def resolve_priority_references(self, user_prompt: str) -> Dict[str, Any]:
        """Enhanced priority resolution for multi-value scenarios"""
        import re

        priority_mapping = {
            'low': 1,
            'very low': 1,
            'medium': 2,
            'normal': 2,
            'high': 3,
            'urgent': 4,
            'critical': 4,
            'very high': 4
        }

        print(f"ğŸ” Advanced priority analysis: '{user_prompt}'")

        # Exclusion patterns
        exclusion_patterns = [
            r'(?:not|except|excluding|without)\s+(?:priority\s+)?(?:is\s+)?([a-z\s,]+?)(?:\s|$)',
            r'priority\s+(?:is\s+)?(?:not|except|excluding)\s+([a-z\s,]+?)(?:\s|$)'
        ]

        excluded_priorities = {}
        for pattern in exclusion_patterns:
            matches = re.findall(pattern, user_prompt.lower())
            for match in matches:
                print(f"ğŸš« Found priority exclusion: '{match}'")
                excluded_parts = self._parse_status_list(match, priority_mapping)
                excluded_priorities.update(excluded_parts)

        # Inclusion patterns - ENHANCED to properly capture multiple priority values
        inclusion_patterns = [
            # Enhanced pattern for comma-separated priorities: "priority is high, medium, low"
            r'priority\s+(?:is|are|in|includes?)\s+([a-z\s,]+?)(?:\s+(?:and|or)\s+(?!priority)[a-z\s,]+?)*',
            # Pattern for "priority is X and Y" format
            r'priority\s+(?:is|are|equals?)\s+([a-z\s,]+?)(?:\s+and\s+(?!priority)[a-z\s,]+?)*',
            # Pattern for "priority as X" format
            r'priority\s+(?:as)\s+([a-z\s,]+?)(?:\s+and\s+(?!priority)|$)',
            # Pattern for "with/having priority X, Y"
            r'(?:with|having)\s+priority\s+([a-z\s,]+?)(?:\s+(?:and|or)\s+[a-z\s,]+?)*',
            # Pattern for "X priority" format
            r'((?:high|medium|low|urgent|critical))\s+priority',
            # Enhanced pattern for simple "priority is X" that captures everything until end or next field
            r'priority\s+(?:is|are|equals?)\s+([a-z\s,]+?)(?=\s+and\s+(?:status|urgency|category|assignee|requester)|$)'
        ]

        included_priorities = {}

        # Parse explicit priority mentions
        for pattern in inclusion_patterns:
            matches = re.findall(pattern, user_prompt.lower())
            for match in matches:
                print(f"ğŸ¯ Found priority pattern: '{match}'")
                parsed_priorities = self._parse_status_list(match, priority_mapping)
                included_priorities.update(parsed_priorities)

        result = {
            'included': included_priorities,
            'excluded': excluded_priorities,
            'operator': 'not_in' if excluded_priorities and not included_priorities else 'in'
        }

        print(f"ğŸ¯ Priority resolution result: {result}")
        return result

    def _add_multi_value_filter(self, quals: list, filter_result: Dict[str, Any], field_key: str, filter_type: str):
        """Add multi-value filter with inclusion/exclusion support"""
        if not filter_result or (not filter_result.get('included') and not filter_result.get('excluded')):
            return

        # Handle inclusion filters
        if filter_result.get('included'):
            included_ids = list(filter_result['included'].values())
            print(f"ğŸ¯ Creating {filter_type} inclusion filter: {included_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": field_key
                },
                "operator": "in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": included_ids
                    }
                }
            })

        # Handle exclusion filters
        if filter_result.get('excluded'):
            excluded_ids = list(filter_result['excluded'].values())
            print(f"ğŸ¯ Creating {filter_type} exclusion filter: {excluded_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": field_key
                },
                "operator": "not_in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": excluded_ids
                    }
                }
            })

    def _add_category_filter(self, quals: list, category_result: Dict[str, Any]):
        """Add category filter using VariableOperandRest structure"""
        if not category_result or (not category_result.get('included') and not category_result.get('excluded')):
            return

        # Handle inclusion filters
        if category_result.get('included'):
            included_ids = list(category_result['included'].values())
            print(f"ğŸ¯ Creating category inclusion filter: {included_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "VariableOperandRest",
                    "value": "categoryId"
                },
                "operator": "in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": included_ids
                    }
                }
            })

        # Handle exclusion filters
        if category_result.get('excluded'):
            excluded_ids = list(category_result['excluded'].values())
            print(f"ğŸ¯ Creating category exclusion filter: {excluded_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "VariableOperandRest",
                    "value": "categoryId"
                },
                "operator": "not_in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": excluded_ids
                    }
                }
            })

    def _add_department_filter(self, quals: list, department_result: Dict[str, Any]):
        """Add department filter using VariableOperandRest structure"""
        if not department_result or (not department_result.get('included') and not department_result.get('excluded')):
            return

        # Handle inclusion filters
        if department_result.get('included'):
            included_ids = list(department_result['included'].values())
            print(f"ğŸ¯ Creating department inclusion filter: {included_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "VariableOperandRest",
                    "value": "departmentId"
                },
                "operator": "in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": included_ids
                    }
                }
            })

        # Handle exclusion filters
        if department_result.get('excluded'):
            excluded_ids = list(department_result['excluded'].values())
            print(f"ğŸ¯ Creating department exclusion filter: {excluded_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "VariableOperandRest",
                    "value": "departmentId"
                },
                "operator": "not_in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": excluded_ids
                    }
                }
            })

    def _add_subject_filter(self, quals: list, subject_result: Dict[str, Any]):
        """Add subject filter using PropertyOperandRest structure"""
        if not subject_result or not subject_result.get('filters'):
            return

        for subject_filter in subject_result['filters']:
            text = subject_filter.get('text', '')
            operator = subject_filter.get('operator', 'contains')

            if text:
                print(f"ğŸ¯ Creating subject {operator} filter: '{text}'")
                quals.append({
                    "type": "RelationalQualificationRest",
                    "leftOperand": {
                        "type": "PropertyOperandRest",
                        "key": "request.subject"
                    },
                    "operator": operator,
                    "rightOperand": {
                        "type": "ValueOperandRest",
                        "value": {
                            "type": "StringValueRest",
                            "value": text
                        }
                    }
                })

    def _add_business_logic_filters(self, quals: list, user_prompt: str):
        """Add complex business logic filters"""
        prompt_lower = user_prompt.lower()

        # VIP customer handling
        if any(term in prompt_lower for term in ['vip', 'important', 'critical customer']):
            print("ğŸ¯ Adding VIP customer filter")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": "request.vipRequest"
                },
                "operator": "equal",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "BooleanValueRest",
                        "value": True
                    }
                }
            })

        # Escalation scenarios
        if any(term in prompt_lower for term in ['escalated', 'overdue', 'sla violation']):
            print("ğŸ¯ Adding escalation filter")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": "request.slaViolated"
                },
                "operator": "equal",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "BooleanValueRest",
                        "value": True
                    }
                }
            })

        # Time-based business logic
        if any(term in prompt_lower for term in ['recent', 'today', 'this week']):
            print("ğŸ¯ Adding recent time filter")
            if 'today' in prompt_lower:
                duration_value = 1
                duration_unit = "days"
            elif 'this week' in prompt_lower:
                duration_value = 7
                duration_unit = "days"
            else:  # recent
                duration_value = 3
                duration_unit = "days"

            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "VariableOperandRest",
                    "key": "created_date"
                },
                "operator": "within_last",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "DurationValueRest",
                        "value": duration_value,
                        "unit": duration_unit
                    }
                }
            })

    def _validate_filter_values(self, filter_values: list, filter_type: str) -> list:
        """Validate and optimize filter values"""
        if not filter_values:
            print(f"âš ï¸ Empty {filter_type} filter values - skipping")
            return []

        # Remove duplicates while preserving order
        unique_values = list(dict.fromkeys(filter_values))

        # Check for large value sets
        if len(unique_values) > 100:
            print(f"âš ï¸ Large {filter_type} filter set ({len(unique_values)} values) - consider optimization")

        # Validate data types
        for value in unique_values:
            if not isinstance(value, (int, float)):
                print(f"âš ï¸ Invalid {filter_type} value type: {type(value)} for value {value}")
                return []

        print(f"âœ… Validated {filter_type} filter: {len(unique_values)} unique values")
        return unique_values

    def _detect_conflicting_filters(self, quals: list) -> bool:
        """Detect potentially conflicting filter combinations"""
        status_filters = []
        priority_filters = []

        for qual in quals:
            if qual.get("leftOperand", {}).get("key") == "request.statusId":
                status_filters.append(qual)
            elif qual.get("leftOperand", {}).get("key") == "request.priorityId":
                priority_filters.append(qual)

        # Check for conflicting status filters
        has_inclusion = any(f.get("operator") == "in" for f in status_filters)
        has_exclusion = any(f.get("operator") == "not_in" for f in status_filters)

        if has_inclusion and has_exclusion:
            print("âš ï¸ Detected both inclusion and exclusion status filters - may cause conflicts")
            return True

        # Check for business logic conflicts
        closed_included = False
        open_included = False

        for qual in status_filters:
            if qual.get("operator") == "in":
                values = qual.get("rightOperand", {}).get("value", {}).get("value", [])
                if 13 in values:  # Closed status
                    closed_included = True
                if 9 in values:   # Open status
                    open_included = True

        if closed_included and open_included:
            print("âš ï¸ Including both Open and Closed statuses - this may be intentional but unusual")

        return False

    def build_qualification_for_endpoint(self, endpoint: str, user_prompt: str) -> Dict:
        """Build qualification based on endpoint and user prompt"""
        if endpoint == 'requests':
            return self.build_request_qualification(user_prompt)
        elif endpoint == 'service_catalog':
            return self.build_service_catalog_qualification(user_prompt)
        elif endpoint == 'users':
            return {}  # Users endpoint doesn't need qualification
        elif endpoint == 'urgency':
            return {}  # Urgency endpoint doesn't need qualification
        else:
            return {}

    def build_request_qualification(self, user_prompt: str) -> Dict:
        """Build qualification for request search"""
        quals = []

        # Resolve references with enhanced multi-value support
        user_refs = self.resolve_user_references(user_prompt)
        urgency_refs = self.resolve_urgency_references(user_prompt)
        status_result = self.resolve_status_references(user_prompt)
        priority_result = self.resolve_priority_references(user_prompt)
        category_result = self.resolve_category_references(user_prompt)
        department_result = self.resolve_department_references(user_prompt)
        subject_result = self.resolve_subject_references(user_prompt)

        # Add status filter - Enhanced for inclusion/exclusion scenarios
        self._add_multi_value_filter(quals, status_result, "request.statusId", "status")

        # Add priority filter - Enhanced for inclusion/exclusion scenarios
        self._add_multi_value_filter(quals, priority_result, "request.priorityId", "priority")

        # Add category filter - Enhanced for inclusion/exclusion scenarios (using VariableOperandRest)
        self._add_category_filter(quals, category_result)

        # Add department filter - Enhanced for inclusion/exclusion scenarios (using VariableOperandRest)
        self._add_department_filter(quals, department_result)

        # Add subject filter - Enhanced for contains/equals scenarios
        self._add_subject_filter(quals, subject_result)

        # Add business logic filters for complex scenarios
        self._add_business_logic_filters(quals, user_prompt)

        # Add urgency filter - Enhanced for multiple values
        if urgency_refs:
            urgency_ids = list(urgency_refs.values())
            print(f"ğŸ¯ Creating urgency filter with multiple values: {urgency_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": "request.urgencyId"
                },
                "operator": "in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": urgency_ids
                    }
                }
            })

        # Add user/assignee filter - Enhanced for multiple values
        if user_refs:
            user_ids = list(user_refs.values())
            print(f"ğŸ¯ Creating user filter with multiple values: {user_ids}")
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": "request.technicianId"
                },
                "operator": "in",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "ListLongValueRest",
                        "value": user_ids
                    }
                }
            })

        # Add text search filters
        text_searches = self.extract_text_search(user_prompt)
        for field, search_term in text_searches.items():
            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": f"request.{field}"
                },
                "operator": "contains",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "StringValueRest",
                        "value": search_term
                    }
                }
            })

        # Check if prompt has any filtering conditions
        has_filters = (status_result.get('included') or status_result.get('excluded') or
                      priority_result.get('included') or priority_result.get('excluded') or
                      urgency_refs or user_refs or text_searches)

        # Check if prompt is asking for "all" without conditions
        prompt_lower = user_prompt.lower()
        is_general_query = any(pattern in prompt_lower for pattern in [
            'get all requests', 'show all requests', 'list all requests',
            'get all the request', 'show all the request', 'list all the request',
            'all requests', 'all the request'
        ]) and not has_filters

        # If it's a general query without conditions, return empty quals
        if is_general_query:
            print("ğŸ“‹ General query detected - returning empty qualification")
            # Return empty quals for general queries
            pass  # quals remains empty
        elif not quals and not has_filters:
            # Only add default filter if there are some conditions but no specific filters matched
            # This handles edge cases where we have some text but no clear filters
            if any(word in prompt_lower for word in ['priority', 'status', 'assignee', 'subject', 'urgent', 'high', 'low', 'open', 'closed']):
                quals.append({
                    "type": "RelationalQualificationRest",
                    "leftOperand": {
                        "type": "PropertyOperandRest",
                        "key": "request.statusId"
                    },
                    "operator": "not_in",
                    "rightOperand": {
                        "type": "ValueOperandRest",
                        "value": {
                            "type": "ListLongValueRest",
                            "value": [13]  # Closed status ID
                        }
                    }
                })

        # Validate and optimize the final qualification
        if quals:
            print(f"ğŸ” Validating qualification with {len(quals)} filters")

            # Detect conflicting filters
            has_conflicts = self._detect_conflicting_filters(quals)
            if has_conflicts:
                print("âš ï¸ Potential filter conflicts detected - review query logic")

            # Validate individual filter values
            for qual in quals:
                if qual.get("rightOperand", {}).get("value", {}).get("type") == "ListLongValueRest":
                    field_key = qual.get("leftOperand", {}).get("key", "unknown")
                    values = qual.get("rightOperand", {}).get("value", {}).get("value", [])
                    validated_values = self._validate_filter_values(values, field_key)

                    # Update with validated values
                    if validated_values != values:
                        qual["rightOperand"]["value"]["value"] = validated_values

            print(f"âœ… Qualification validation complete")
        else:
            print("ğŸ“‹ Empty qualification - no filters applied")

        return {
            "qualDetails": {
                "type": "FlatQualificationRest",
                "quals": quals
            }
        }

    def build_service_catalog_qualification(self, user_prompt: str) -> Dict:
        """Build qualification for service catalog search"""
        quals = []

        # Extract text search for service catalog
        text_searches = self.extract_text_search(user_prompt)
        for field, search_term in text_searches.items():
            # Map request fields to service catalog fields
            if field == 'subject':
                field = 'name'  # Service catalog uses 'name' instead of 'subject'

            quals.append({
                "type": "RelationalQualificationRest",
                "leftOperand": {
                    "type": "PropertyOperandRest",
                    "key": f"serviceCatalog.{field}"
                },
                "operator": "contains",
                "rightOperand": {
                    "type": "ValueOperandRest",
                    "value": {
                        "type": "StringValueRest",
                        "value": search_term
                    }
                }
            })

        # Look for specific service catalog names
        catalog_mapping = self.get_service_catalog_mapping()
        import re

        catalog_patterns = [
            r'(?:service|catalog)\s+(?:named|called|is)\s+(\w+)',
            r'(?:on-boarding|off-boarding|laptop)',
            r'employee\s+(?:on-boarding|off-boarding)'
        ]

        for pattern in catalog_patterns:
            matches = re.findall(pattern, user_prompt.lower())
            for match in matches:
                if match in catalog_mapping:
                    quals.append({
                        "type": "RelationalQualificationRest",
                        "leftOperand": {
                            "type": "PropertyOperandRest",
                            "key": "serviceCatalog.id"
                        },
                        "operator": "in",
                        "rightOperand": {
                            "type": "ValueOperandRest",
                            "value": {
                                "type": "ListLongValueRest",
                                "value": [catalog_mapping[match]]
                            }
                        }
                    })

        return {
            "qualDetails": {
                "type": "FlatQualificationRest",
                "quals": quals
            }
        } if quals else {}

    def extract_text_search(self, user_prompt: str) -> Dict[str, str]:
        """Extract text search terms from user prompt"""
        prompt_lower = user_prompt.lower()
        text_searches = {}

        import re

        # Specific field patterns
        field_patterns = {
            'subject': [
                r'subject\s+(?:contains|has|includes|with)\s+["\']([^"\']+)["\']',
                r'subject\s+(?:contains|has|includes|with)\s+(\w+)',
                r'subject\s+(?:is|equals?)\s+(\w+)'  # Added "is" pattern
            ],
            'description': [
                r'description\s+(?:contains|has|includes|with)\s+["\']([^"\']+)["\']',
                r'description\s+(?:contains|has|includes|with)\s+(\w+)',
                r'description\s+(?:is|equals?)\s+(\w+)'  # Added "is" pattern
            ],
            'name': [
                r'(?:name|title)\s+(?:contains|has|includes|with)\s+["\']([^"\']+)["\']',
                r'(?:name|title)\s+(?:contains|has|includes|with)\s+(\w+)',
                r'(?:name|title)\s+(?:is|equals?)\s+(\w+)'  # Added "is" pattern
            ]
        }

        for field, patterns in field_patterns.items():
            for pattern in patterns:
                match = re.search(pattern, prompt_lower)
                if match:
                    text_searches[field] = match.group(1)
                    break

        # General text search patterns
        if not text_searches:
            general_patterns = [
                r'contains\s+["\']([^"\']+)["\']',
                r'contains\s+(\w+)',
                r'having\s+["\']([^"\']+)["\']',
                r'having\s+(\w+)',
                r'includes\s+["\']([^"\']+)["\']',
                r'includes\s+(\w+)'
            ]

            for pattern in general_patterns:
                match = re.search(pattern, prompt_lower)
                if match:
                    search_term = match.group(1)

                    # Skip system terms
                    skip_terms = ['unassigned', 'assigned', 'technician', 'status', 'priority', 'urgency']
                    if search_term not in skip_terms:
                        text_searches['subject'] = search_term
                        break

        return text_searches

    def execute_query(self, user_prompt: str) -> Dict:
        """Execute query based on user prompt"""
        print(f"ğŸš€ Processing query: {user_prompt}")

        # Detect endpoint
        endpoint = self.detect_endpoint_from_prompt(user_prompt)

        # Build qualification
        qualification = self.build_qualification_for_endpoint(endpoint, user_prompt)

        # Execute API request
        if endpoint == 'users':
            # Users endpoint doesn't need qualification
            response = self.make_api_request('users')
        elif endpoint == 'urgency':
            # Urgency endpoint doesn't need qualification
            response = self.make_api_request('urgency')
        elif endpoint == 'service_catalog':
            # Service catalog with pagination
            response = self.make_api_request('service_catalog', qualification, {'offset': 0, 'size': 1000})
        else:
            # Default to requests
            response = self.make_api_request('requests', qualification)

        return {
            'endpoint': endpoint,
            'qualification': qualification,
            'response': response,
            'user_prompt': user_prompt
        }

    def train_from_data(self):
        """Train the agent with comprehensive API knowledge from training data"""

        # Training data from Training_data1.pdf
        training_knowledge = """
        # ITSM Multi-Endpoint API Training Data

        ## 1. URGENCY API
        **Endpoint:** /api/urgency/search/byqual
        **Method:** POST
        **Description:** Fetch urgency levels mapping
        **Usage:** When user mentions urgency levels like "high", "low", "medium", "urgent"

        **Urgency Mapping:**
        - ID 1: "Low" (systemName: "Low")
        - ID 2: "Medium" (systemName: "Medium")
        - ID 3: "High" (systemName: "High")
        - ID 4: "Urgent" (systemName: "Urgent")

        **Example Query:** "Get all requests with urgency as high" â†’ Use urgency ID 3

        ## 2. SERVICE CATALOG API
        **Endpoint:** /api/service_catalog/search/byqual
        **Method:** POST
        **Description:** Search service catalog items
        **Usage:** When user mentions service catalogs, templates, onboarding, etc.

        **Service Catalog Items:**
        - ID 1: "Employee On-boarding" (subject: "Employee On-boarding")
        - ID 2: "Employee Off-boarding" (subject: "Employee Off-boarding")
        - ID 3: "Laptop" (subject: "Request for New Laptop")

        **Fields:**
        - id: Unique service catalog ID
        - name: Service catalog name
        - subject: Service catalog subject
        - description: Detailed description
        - categoryId: Category ID
        - serviceCatalogStatus: Status (draft, active, etc.)

        ## 3. USERS/TECHNICIAN API
        **Endpoint:** /api/technician/active/list
        **Method:** GET
        **Description:** Get active technicians/users list
        **Usage:** When user mentions technicians, users, assignees by name

        **User Fields:**
        - userId: Unique user ID
        - name: User display name
        - email: User email address
        - userName: System username
        - itsmUserType: User type (technician, etc.)

        **Example User:**
        - ID 1: "AutoMind" (email: "automind@motadata.com")

        ## 4. REQUEST SEARCH API (Enhanced)
        **Endpoint:** /api/request/search/byqual
        **Method:** POST
        **Description:** Search and filter IT service requests
        **Usage:** Default endpoint for request-related queries

        **Enhanced Filters:**
        - urgencyId: Use urgency API to resolve names to IDs
        - technicianId: Use users API to resolve names to IDs
        - statusId: Use status API to resolve names to IDs
        - priorityId: Use priority mapping

        ## AUTOMATIC RESOLUTION LOGIC

        1. **User Name Resolution:**
           - If query mentions assignee/technician names â†’ Call users API
           - Map name to userId â†’ Use in technicianId filter

        2. **Urgency Resolution:**
           - If query mentions urgency levels â†’ Call urgency API
           - Map urgency name to urgencyId â†’ Use in urgencyId filter

        3. **Service Catalog Resolution:**
           - If query mentions service catalogs â†’ Call service catalog API
           - Map catalog name to catalogId â†’ Use in filters

        ## QUERY PATTERNS

        **Urgency Queries:**
        - "Get requests with urgency as high" â†’ urgencyId = 3
        - "Show me urgent requests" â†’ urgencyId = 4
        - "Find low urgency tickets" â†’ urgencyId = 1

        **User Assignment Queries:**
        - "Get requests assigned to AutoMind" â†’ technicianId = 1
        - "Show me tickets for AutoMind" â†’ technicianId = 1
        - "Find unassigned requests" â†’ technicianId IS NULL

        **Service Catalog Queries:**
        - "Show employee onboarding catalogs" â†’ name CONTAINS "onboarding"
        - "Find laptop service catalog" â†’ name = "Laptop"
        - "Get all service catalogs" â†’ No filter

        **Multi-Filter Queries:**
        - "Get high urgency requests assigned to AutoMind" â†’ urgencyId = 3 AND technicianId = 1
        """

        print("ğŸ“š Training agent with comprehensive API knowledge...")
        print("âœ… Urgency API mapping loaded")
        print("âœ… Service Catalog API patterns loaded")
        print("âœ… Users API resolution logic loaded")
        print("âœ… Request API enhanced filtering loaded")
        print("âœ… Multi-endpoint detection logic loaded")
        print("ğŸ¯ Agent training complete!")

        return training_knowledge
